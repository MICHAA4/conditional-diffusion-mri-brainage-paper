{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21394f42-5fbe-4b2e-8bb3-cb4d6defae51",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b6e6a-2aad-4770-9fbe-34fd5e1dc972",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0a006-5891-463e-ad53-f1c350c2989f",
   "metadata": {},
   "source": [
    "## Setup Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f2921-5816-4cf5-858c-e516f543a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    Lambdad,\n",
    "    Resized,\n",
    "    Randomizable,\n",
    "    EnsureChannelFirstd,\n",
    "    ScaleIntensityRanged\n",
    ")\n",
    "from monai.config import print_config\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.data import Dataset, CacheDataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generative.inferers import DiffusionInferer\n",
    "from generative.networks.nets import DiffusionModelUNet\n",
    "from generative.networks.schedulers import DDPMScheduler\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74f635-60e9-4b07-aa6d-d4df84aec3da",
   "metadata": {},
   "source": [
    "## Setup Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caeb808-a81c-4383-ba04-3eaad4e87d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa21e8-5b14-4f16-bf08-6e2cf4dbbfbc",
   "metadata": {},
   "source": [
    "## Set Deterministic Training for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795a093-2baa-49ac-bfc7-fd3ae66bd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c529070e-78d7-40e7-af20-6380e8c08463",
   "metadata": {},
   "source": [
    "## CamcanDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9eccd-1d9c-444d-9581-021be560058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamcanDataset(Randomizable, CacheDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir,\n",
    "        csv_file,\n",
    "        section,\n",
    "        transform=None,\n",
    "        seed=0,\n",
    "        val_frac=0.2,\n",
    "        test_frac=0.2,\n",
    "        cache_num=sys.maxsize,\n",
    "        cache_rate=1.0,\n",
    "        num_workers=0,\n",
    "        progress: bool = True,\n",
    "        condition_prob = 0,\n",
    "    ) -> None:\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(\"Root directory root_dir must be a directory.\")\n",
    "        self.root_dir = root_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.section = section\n",
    "        self.val_frac = val_frac\n",
    "        self.test_frac = test_frac\n",
    "        self.condition_prob = condition_prob\n",
    "        self.set_random_state(seed=seed)\n",
    "\n",
    "        data = self._generate_data_list()\n",
    "\n",
    "        CacheDataset.__init__(\n",
    "            self,\n",
    "            data=data,\n",
    "            transform=transform,\n",
    "            cache_num=cache_num,\n",
    "            cache_rate=cache_rate,\n",
    "            num_workers=num_workers,\n",
    "            progress=progress,\n",
    "        )\n",
    "\n",
    "    def randomize(self, data: np.ndarray) -> None:\n",
    "        self.R.shuffle(data)\n",
    "\n",
    "    def _generate_data_list(self):\n",
    "        datalist = []\n",
    "        with open(self.csv_file, mode='r') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                image_path = os.path.join(self.root_dir, f\"sub-{row['Subject']}_defaced_T1.nii.gz\")\n",
    "                if not os.path.exists(image_path):\n",
    "                    continue\n",
    "                img = nib.load(image_path)\n",
    "                img_data = img.get_fdata()\n",
    "                for slice_idx in range(img_data.shape[2]//2 - 20, img_data.shape[2]//2 + 20):  # Assuming axial slices\n",
    "                    slice_data = img_data[:,:,slice_idx]\n",
    "                    condition = np.array([\n",
    "                        [int(row['Age'])],\n",
    "                        [int(row['Sex'])],\n",
    "                        [slice_idx]\n",
    "                    ]).reshape((1,3)).astype('float32')\n",
    "                    datalist.append({\n",
    "                        \"image\": slice_data,\n",
    "                        \"condition\": condition\n",
    "                    })\n",
    "        \n",
    "        length = len(datalist)\n",
    "        indices = np.arange(length)\n",
    "        self.randomize(indices)\n",
    "\n",
    "        # train, validation, test split\n",
    "        test_length = int(length * self.test_frac)\n",
    "        val_length = int(length * self.val_frac)\n",
    "        if self.section == \"test\":\n",
    "            section_indices = indices[:test_length]\n",
    "        elif self.section == \"validation\":\n",
    "            section_indices = indices[test_length : test_length + val_length]\n",
    "        elif self.section == \"training\":\n",
    "            section_indices = indices[test_length + val_length :]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f'Unsupported section: {self.section}, available options are [\"training\", \"validation\", \"test\"].'\n",
    "            )\n",
    "        return [datalist[i] for i in section_indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "\n",
    "        if random.random() < self.condition_prob:\n",
    "            sample[\"condition\"] = np.array([[-1, -1, -1]])\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec73a0-5dc4-4dec-b93f-9b1347a3696c",
   "metadata": {},
   "source": [
    "## Setup CamcanDataset and Training and Validation DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7bb11-05aa-44ba-87a9-6556d9272095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "data_dir = \"./dataset_camcan_sy\"\n",
    "csv_file = \"./phenotype.csv\"\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        EnsureChannelFirstd(keys=[\"image\"], channel_dim='no_channel'),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0),\n",
    "        Lambdad(keys=[\"condition\"], func=lambda x: torch.tensor(x, dtype=torch.float32)),\n",
    "        Resized(keys=[\"image\"], spatial_size=(96,128)),\n",
    "    ])\n",
    "\n",
    "\n",
    "# Training DataLoader\n",
    "train_ds = CamcanDataset(root_dir=data_dir, csv_file=csv_file, transform=train_transforms, section=\"training\", condition_prob=0.2)\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=8, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b363c2c4-892c-4740-86a5-d6b438031e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = Compose(\n",
    "    [\n",
    "        EnsureChannelFirstd(keys=[\"image\"], channel_dim='no_channel'),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0),\n",
    "        Lambdad(keys=[\"condition\"], func=lambda x: torch.tensor(x, dtype=torch.float32)),\n",
    "        Resized(keys=[\"image\"], spatial_size=(96,128)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Validation DataLoader\n",
    "val_ds = CamcanDataset(root_dir=data_dir, csv_file=csv_file, transform=val_transforms, section=\"validation\")\n",
    "val_loader = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=8, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e61b5c-69a6-4a33-b039-ab24559c4315",
   "metadata": {},
   "source": [
    "## Visualisation of Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded352fa-a0be-49f0-aaf0-4925af58b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = next(iter(train_loader))\n",
    "print(f\"batch shape: {check_data['image'].shape}\")\n",
    "first_image = check_data['image'][0, 0]  # Accessing the first image from the batch\n",
    "condition = check_data['condition'][0] # Accessing the condition for the first image\n",
    "print(check_data['condition'])\n",
    "print(check_data['condition'].shape)\n",
    "\n",
    "age = condition[0, 0]\n",
    "sex = condition[0, 1]\n",
    "slice_number = condition[0, 2]\n",
    "\n",
    "# Plot the first image\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(first_image, cmap='gray')\n",
    "plt.title(f\"Age: {age}, Sex: {sex}, Slice Number: {slice_number}\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb88a2d-000b-409a-b698-6f27ad7a1277",
   "metadata": {},
   "source": [
    "## Define Network, Scheduler, Optimizer and Inferer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8ea30-9b88-4152-b3bc-51019c1c00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = DiffusionModelUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    num_channels=(256, 256, 512),\n",
    "    attention_levels=(False, False, True),\n",
    "    num_res_blocks=2,\n",
    "    num_head_channels=(0, 0, 512),\n",
    "    with_conditioning=True,\n",
    "    cross_attention_dim=3,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=2.5e-5)\n",
    "\n",
    "inferer = DiffusionInferer(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608f0dc-71bd-4ba0-93e9-1e2ed9bcff93",
   "metadata": {},
   "source": [
    "## Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d404c-7d08-4e5e-8303-6ebdbcb71d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the pretrained model\n",
    "pretrained_model_path = 'pretrained_model_275.pth'\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load(pretrained_model_path, map_location=device)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# If you have a checkpoint with more information (like optimizer state), use this:\n",
    "checkpoint = torch.load('pretrained_model_checkpoint_275.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch']\n",
    "print(start_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87085670-f892-4e89-aa2d-63e2c77f3fec",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac413f-a13a-4d58-bc99-bceb18bb21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "val_interval = 25\n",
    "epoch_loss_list = []\n",
    "val_epoch_loss_list = []\n",
    "epoch_loss_list = checkpoint['epoch_loss']\n",
    "val_epoch_loss_list = checkpoint['val_epoch_loss']\n",
    "\n",
    "end_epoch = start_epoch + 1 + n_epochs\n",
    "\n",
    "scaler = GradScaler()\n",
    "total_start = time.time()\n",
    "for epoch in range(start_epoch+1, end_epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), ncols=70)\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "    for step, batch in progress_bar:\n",
    "        images = batch[\"image\"].to(device)\n",
    "        conditions = batch[\"condition\"].to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(enabled=True):\n",
    "            # Generate random noise\n",
    "            noise = torch.randn_like(images).to(device)\n",
    "\n",
    "            # Create timesteps\n",
    "            timesteps = torch.randint(\n",
    "                0, inferer.scheduler.num_train_timesteps, (images.shape[0],), device=images.device\n",
    "            ).long()\n",
    "\n",
    "            # Get model prediction\n",
    "            noise_pred = inferer(inputs=images, diffusion_model=model, noise=noise, timesteps=timesteps, condition=conditions)\n",
    "            loss = F.mse_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": epoch_loss / (step + 1)})\n",
    "    epoch_loss_list.append(epoch_loss / (step + 1))\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        for step, batch in enumerate(val_loader):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            conditions = batch[\"condition\"].to(device)\n",
    "            with torch.no_grad():\n",
    "                with autocast(enabled=True):\n",
    "                    noise = torch.randn_like(images).to(device)\n",
    "                    timesteps = torch.randint(\n",
    "                        0, inferer.scheduler.num_train_timesteps, (images.shape[0],), device=images.device\n",
    "                    ).long()\n",
    "                    noise_pred = inferer(inputs=images, diffusion_model=model, noise=noise, timesteps=timesteps, condition=conditions)\n",
    "                    val_loss = F.mse_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "            val_epoch_loss += val_loss.item()\n",
    "            progress_bar.set_postfix({\"val_loss\": val_epoch_loss / (step + 1)})\n",
    "        val_epoch_loss_list.append(val_epoch_loss / (step + 1))\n",
    "    \n",
    "    torch.save(model.state_dict(), 'pretrained_model_150.pth')\n",
    "\n",
    "# Optionally save a checkpoint with more information\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'epoch_loss': epoch_loss_list,\n",
    "    'val_epoch_loss': val_epoch_loss_list,\n",
    "}\n",
    "torch.save(checkpoint, 'pretrained_model_checkpoint_150.pth')\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(f\"train completed, total time: {total_time}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c39685-9192-4f58-9991-14121c823484",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac036c0d-3ede-4f50-8a25-446f031bfae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8\")\n",
    "plt.title(\"Learning Curves\", fontsize=20)\n",
    "plt.plot(np.linspace(1, end_epoch, end_epoch), epoch_loss_list, color=\"C0\", linewidth=2.0, label=\"Train\")\n",
    "plt.plot(\n",
    "    np.linspace(val_interval, end_epoch, int(end_epoch / val_interval)),\n",
    "    val_epoch_loss_list,\n",
    "    color=\"C1\",\n",
    "    linewidth=2.0,\n",
    "    label=\"Validation\",\n",
    ")\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.xlabel(\"Epochs\", fontsize=16)\n",
    "plt.ylabel(\"Loss\", fontsize=16)\n",
    "plt.legend(prop={\"size\": 14})\n",
    "plt.savefig('Learning_curves_150.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b70f4-05b1-43b0-88a6-2bd3a2378b64",
   "metadata": {},
   "source": [
    "## Sampling Process With Classifier Free Guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f72a45-6c64-4352-b3ea-aa0e9acf5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "guidance_scale = 2.0\n",
    "\n",
    "condition_set = [[18, 2, 45],\n",
    "                [28, 1, 45],\n",
    "                [38, 2, 45],\n",
    "                [48, 1, 45],\n",
    "                [58, 1, 45],\n",
    "                [68, 1, 45],\n",
    "                [78, 1, 45],\n",
    "                [88, 1, 45]]\n",
    "num_condition = len(condition_set)\n",
    "conditioning = []\n",
    "\n",
    "for case in condition_set:\n",
    "    age, sex, slice_number = case\n",
    "    # Create the conditioning tensors and reshape them to (1, 3)\n",
    "    unconditioned = torch.tensor([[-1, -1, -1]], dtype=torch.float32)  # Shape: (1, 3)\n",
    "    conditioned = torch.tensor([[age, sex, slice_number]], dtype=torch.float32)  # Shape: (1, 3)\n",
    "    conditioning.append(torch.stack([unconditioned, conditioned], dim=0).to(device))\n",
    "\n",
    "noise_cases = []\n",
    "\n",
    "for idx in range(num_condition):\n",
    "    noise = torch.randn((1, 1, 96, 128))\n",
    "    noise = noise.to(device)\n",
    "    scheduler.set_timesteps(num_inference_steps=1000)\n",
    "    progress_bar = tqdm(scheduler.timesteps)\n",
    "    \n",
    "    case_conditioning = conditioning[idx]\n",
    "    for t in progress_bar:\n",
    "        with autocast(enabled=True):\n",
    "            with torch.no_grad():\n",
    "                noise_input = torch.cat([noise] * 2)\n",
    "                model_output = model(noise_input, timesteps=torch.Tensor((t,)).to(noise.device), context=case_conditioning)\n",
    "                noise_pred_uncond, noise_pred_text = model_output.chunk(2)\n",
    "                noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "        noise, _ = scheduler.step(noise_pred, t, noise)\n",
    "    noise_cases.append(noise)\n",
    "\n",
    "    # Save the raw noise image as a PNG file with scaling and grayscale\n",
    "    noise_image = noise_cases[idx][0, 0].cpu().numpy()\n",
    "    # Scale the data to 0-1\n",
    "    noise_image = np.clip(noise_image, 0, 1)\n",
    "    # Convert to 8-bit (0-255)\n",
    "    noise_image = (noise_image * 255).astype(np.uint8)\n",
    "    # Create and save the image using PIL\n",
    "    img = Image.fromarray(noise_image, mode='L')\n",
    "    img.save(f'noise_image_{idx + 1}.png')\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(num_condition):\n",
    "    plt.subplot(1, num_condition, i+1)\n",
    "    plt.imshow(noise_cases[i][0, 0].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.title(f\"Image {i+1}\")\n",
    "    plt.tight_layout()\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed11e8-d018-46f8-9426-ea69f30c9dc2",
   "metadata": {},
   "source": [
    "## Clean up Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289d1e2-7ab5-4a2c-a8ae-ec0000ae2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
