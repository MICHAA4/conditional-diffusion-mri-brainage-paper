{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5ed071-6234-449a-87b7-0ba98d5e1181",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce97fd-f092-4e6e-860f-af35d962b96b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d48a51-3f0a-4674-9be8-e0a46cc6c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81fd0d6-c286-4a4d-a4fe-733ac72a36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# monai 설치 확인 및 설치\n",
    "try:\n",
    "    import monai\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"monai-weekly[tqdm]\"])\n",
    "\n",
    "# matplotlib 설치 확인 및 설치\n",
    "try:\n",
    "    import matplotlib\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\"])\n",
    "\n",
    "# matplotlib inline을 대체\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()  # 인터랙티브 모드 활성화\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948acaeb-41b8-4b41-8a5c-f50d053aa29e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1f4ce-b8ad-46d6-9194-cf1060783a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import PIL\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import monai\n",
    "from monai.data import Dataset, CacheDataset, DataLoader\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    Lambdad,\n",
    "    Resized,\n",
    "    Randomizable,\n",
    "    EnsureChannelFirstd,\n",
    "    ScaleIntensityRanged,\n",
    "    RepeatChanneld,\n",
    "    Transposed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf217a-f290-45ce-bb98-e270b37f5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)\n",
    "\n",
    "set_determinism(42)\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30960f57-6b1e-436c-bb07-ceaf18d34343",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"We got a GPU\")\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print(\"Sorry, no GPU for you...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d3246-286f-4e4b-9513-765eb45ab69c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Camcan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a4434-cac3-452e-ab49-66fc568c2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamcanDataset(Randomizable, CacheDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir,\n",
    "        csv_file,\n",
    "        section,\n",
    "        transform=None,\n",
    "        seed=0,\n",
    "        val_frac=0.2,\n",
    "        test_frac=0.2,\n",
    "        cache_num=sys.maxsize,\n",
    "        cache_rate=1.0,\n",
    "        num_workers=0,\n",
    "        progress: bool = True,\n",
    "        condition_prob = 0,\n",
    "    ) -> None:\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(\"Root directory root_dir must be a directory.\")\n",
    "        self.root_dir = root_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.section = section\n",
    "        self.val_frac = val_frac\n",
    "        self.test_frac = test_frac\n",
    "        self.condition_prob = condition_prob\n",
    "        self.set_random_state(seed=seed)\n",
    "\n",
    "        data = self._generate_data_list()\n",
    "\n",
    "        CacheDataset.__init__(\n",
    "            self,\n",
    "            data=data,\n",
    "            transform=transform,\n",
    "            cache_num=cache_num,\n",
    "            cache_rate=cache_rate,\n",
    "            num_workers=num_workers,\n",
    "            progress=progress,\n",
    "        )\n",
    "\n",
    "    def randomize(self, data: np.ndarray) -> None:\n",
    "        self.R.shuffle(data)\n",
    "\n",
    "    def _generate_data_list(self):\n",
    "        datalist = []\n",
    "        with open(self.csv_file, mode='r') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                image_path = os.path.join(self.root_dir, f\"sub-{row['Subject']}_defaced_T1.nii.gz\")\n",
    "                if not os.path.exists(image_path):\n",
    "                    continue\n",
    "                img = nib.load(image_path)\n",
    "                img_data = img.get_fdata()\n",
    "                \n",
    "                for slice_idx in range(img_data.shape[2]//2 - 20, img_data.shape[2]//2 + 20):  # Assuming axial slices\n",
    "                    slice_data = img_data[:,:,slice_idx]\n",
    "                    age = np.array([int(row['Age'])]).astype('float32')\n",
    "                    datalist.append({\n",
    "                        \"image\": slice_data,\n",
    "                        \"age\": age\n",
    "                    })\n",
    "        \n",
    "        length = len(datalist)\n",
    "        indices = np.arange(length)\n",
    "        self.randomize(indices)\n",
    "\n",
    "        # train, validation, test split\n",
    "        test_length = int(length * self.test_frac)\n",
    "        val_length = int(length * self.val_frac)\n",
    "        if self.section == \"test\":\n",
    "            section_indices = indices[:test_length]\n",
    "        elif self.section == \"validation\":\n",
    "            section_indices = indices[test_length : test_length + val_length]\n",
    "        elif self.section == \"training\":\n",
    "            section_indices = indices[test_length + val_length :]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f'Unsupported section: {self.section}, available options are [\"training\", \"validation\", \"test\"].'\n",
    "            )\n",
    "        return [datalist[i] for i in section_indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c0fda-4139-4e10-b76b-d8297cecf38e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00961a0b-6d18-4c93-8305-3a83f39d6e87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c942d-20d6-4d7c-882e-e59cb6dac18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "data_dir = \"./dataset_camcan_sy\"\n",
    "csv_file = \"./phenotype.csv\"\n",
    "\n",
    "# Training DataLoader\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        EnsureChannelFirstd(keys=[\"image\"], channel_dim='no_channel'),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0),\n",
    "        Lambdad(keys=[\"age\"], func=lambda x: torch.tensor(x, dtype=torch.float32)),\n",
    "        Resized(keys=[\"image\"], spatial_size=(96,128)),\n",
    "        RepeatChanneld(keys=[\"image\"], repeats=3),  # (1, H, W) -> (3, H, W)\n",
    "        Transposed(keys=[\"image\"], indices=(1, 2, 0)),\n",
    "    ])\n",
    "\n",
    "train_ds = CamcanDataset(root_dir=data_dir, csv_file=csv_file, transform=train_transforms, section=\"training\", condition_prob=0.2)\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=8, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929563f-516d-4cd0-aba8-e033521d34d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Validation & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74f893-150f-4e3b-b80c-636ba0774fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation & Test DataLoader\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        EnsureChannelFirstd(keys=[\"image\"], channel_dim='no_channel'),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0),\n",
    "        Lambdad(keys=[\"age\"], func=lambda x: torch.tensor(x, dtype=torch.float32)),\n",
    "        Resized(keys=[\"image\"], spatial_size=(96,128)),\n",
    "        RepeatChanneld(keys=[\"image\"], repeats=3),  # (1, H, W) -> (3, H, W)\n",
    "        Transposed(keys=[\"image\"], indices=(1, 2, 0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_ds = CamcanDataset(root_dir=data_dir, csv_file=csv_file, transform=val_transforms, section=\"validation\")\n",
    "val_loader = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=8, persistent_workers=True)\n",
    "\n",
    "test_ds = CamcanDataset(root_dir=data_dir, csv_file=csv_file, transform=val_transforms, section=\"test\")\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False, num_workers=8, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269040e8-70ae-4774-aed5-7c706a4c242c",
   "metadata": {},
   "source": [
    "## Fine-tuning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b26d6-f005-4332-874b-37a404ed882c",
   "metadata": {},
   "source": [
    "### Pytorch -> Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bdff4b-1ae9-4aab-aa29-957b667bd8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_to_numpy(data_loader):\n",
    "    images, ages = [], []\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        batch_cp = copy.deepcopy(batch)  \n",
    "        \n",
    "        img_batch = batch_cp[\"image\"].numpy()  # (batch, 96, 128, 3)\n",
    "        age_batch = batch_cp[\"age\"].numpy()  # (batch, 1)\n",
    "        \n",
    "        del batch\n",
    "        images.append(img_batch)\n",
    "        ages.append(age_batch)\n",
    "        \n",
    "    return np.concatenate(images), np.concatenate(ages)\n",
    "\n",
    "# PyTorch DataLoader → NumPy 변환\n",
    "train_images, train_ages = pytorch_to_numpy(train_loader)\n",
    "val_images, val_ages = pytorch_to_numpy(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a1d4f-30a5-49ef-8a48-60cf94c049b7",
   "metadata": {},
   "source": [
    "### Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d8ea0-db08-4515-9bf1-15e3a7b33c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "lr = 1e-4\n",
    "checkpoint_path = './DeepBrainNet/Models/DBN_model.h5'\n",
    "model = load_model(checkpoint_path, compile=False)\n",
    "\n",
    "# 옵티마이저 및 손실 함수 설정\n",
    "model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "\n",
    "# 콜백 함수 설정\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, verbose=1)\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "#early_stopping_loss = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "checkpoint = ModelCheckpoint(\"./DBN_finetuned/best_{epoch}.h5\", monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a21df51-9591-4a04-84be-59ecf677affb",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46225644-7726-4ae5-b1c3-896c925a0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    x=train_images, y=train_ages,  # train_loader를 fit()에 직접 전달 가능\n",
    "    batch_size=8,\n",
    "    epochs=epochs,\n",
    "    validation_data=(val_images, val_ages),\n",
    "    callbacks=[reduce_lr, checkpoint],\n",
    "    verbose=1  # 1: 자세한 로그 출력 (0: 출력 없음, 2: epoch별 요약만 출력)\n",
    ")\n",
    "\n",
    "# 모델 저장 (마지막 epoch 기준)\n",
    "model.save(\"./DBN_finetuned/last.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
